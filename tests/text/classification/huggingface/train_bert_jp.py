import torch, kktorch
from kktorch.trainer.base import Trainer
from kktorch.data.dataloader import LivedoorNewsDataLoader
from kktorch.nn.configmod import ConfigModule


if __name__ == "__main__":
    # load config file and create network
    network = ConfigModule(
        f"/{kktorch.__path__[0]}/model_zoo/huggingface/bert_jp_classify.json", 
        user_parameters={
            "___n_node": 768,
            "___freeze_layers": [
                "^embeddings",
                "^encoder\\.layer\\.[0-9]\\.",
            ],
            "___n_classes": 9
        },
    )
    """
    >>> dataloader_train.dataset[0]
    ('国内専用モデル「HTC J」投入で本気を出した——「HTC One」に賭けるHTCのスマホ戦略に迫る【山根康宏の“世界のモバイル”】...
    >>> network.tokenizer.tokenize(dataloader_train.dataset[0][0])
    ['国内', '専用', 'モデル', '「', 'HT', '##C', 'J', '」', '投入', 'で', '本気', 'を', '出し', 'た', '—', '##—', '##「', 'HT', '##C', 'One', '」', 'に', '賭け', '##る', 'HT', '##C', 'の', 'スマ', '##ホ', '戦略', 'に', '迫る', '【', '山', '##根', '康', '##宏', 'の', '“', '世界', 'の', 'モバイル', '”', '】', 
    >>> network.tokenizer(dataloader_train.dataset[0][0], **{"padding": True, "max_length": network.tokenizer.model_max_length, "truncation": True})
    {'input_ids': [2, 1216, 2262, 1317, 36, 13075, 28598, 404, 38, 4056, 12, 22614, 11, 2078, 10, 18444, 31123, 28496, 13075, 28598, 14638, 38, 7, 12559, 28449, 13075, 28598, 5, 4430, 28774, 3737, 7, 11848, 9680, 309, 29246, 3221, 30323, 5, 2203, 324, 5, 9307, 1964, 9594, 13075, 28598, 9, 2563, 12, 70, 1409, 40, 36, 13075, 28598, 14638, 38, 2869, 11, 1499, 10733, 2563, 2334, 1227, 895, 2203, 9156, 1207, 1964, 5, 91, 2262, 1317, 12, 130, 6, 3527, 1091, 36, 24846, 3182, 38, 11, 666, 15, 10, 8682, 28, 4459, 5, 13884, 1100, 36, 13075, 28598, 404, 4338, 28865, 483, 13075, 38, 5, 9317, 15347, 14, 12495, 75, 8, 22771, 5, 3759, 81, 18, 1011, 3737, 7, 6236, 84, 16, 33, 972, 28, 31, 3635, 205, 14, 6, 580, 2524, 40, 1011, 3619, 1993, 48, 1207, 11, 10981, 16, 33, 5, 9, 6032, 7, 28, 7316, 14, 102, 16, 5, 45, 3635, 205, 8, 2216, 5, 13075, 28598, 2040, 221, 28, 17732, 10529, 18, 1575, 7, 1334, 6, 705, 49, 3579, 1197, 5, 2808, 64, 28, 26726, 28616, 80, 972, 28, 707, 8, 13075, 28598, 404, 9, 929, 5, 4663, 221, 7771, 2263, 7, 4485, 84, 16, 33, 124, 12, 6, 91, 587, 2486, 5, 5648, 11, 1499, 4106, 28492, 205, 13, 15, 16, 33, 8, 13075, 28598, 9, 2563, 12, 28, 25, 37, 7, 602, 15, 10, 147, 731, 36, 13075, 28598, 14638, 38, 11, 5507, 7, 8682, 15, 16, 206, 6, 1189, 3005, 5, 16750, 13, 2869, 691, 5, 2808, 11, 6399, 16, 33, 8, 13075, 28598, 14638, 731, 7, 9, 113, 3661, 5, 1433, 6, 10770, 21017, 12, 1197, 11, 5090, 10, 180, 6, 1575, 7, 1427, 5, 31, 6243, 3243, 5, 676, 13, 48, 181, 5, 1317, 14, 4060, 26, 20, 16, 33, 8, 1725, 28, 6032, 5, 1197, 687, 12, 9, 332, 6, 10820, 8589, 49, 107, 21990, 18, 705, 1197, 64, 3276, 28724, 28608, 5, 635, 14, 1499, 10733, 26, 20, 16, 33, 8, 91, 1317, 5, 13075, 28598, 404, 28, 6, 2040, 5, 1427, 40, 70, 13075, 28598, 14638, 731, 5, 6075, 11, 12777, 1317, 13, 5517, 3635, 205, 8, 324, 81, 18, 23509, 28494, 877, 5, 2066, 7, 5183, 16, 6, 13075, 28598, 9, 1411, 276, 19, 6624, 11, 21822, 9294, 7, 8858, 16, 322, 10, 8, 785, 19, 97, 17, 755, 17555, 5, 1011, 13003, 9, 482, 18407, 429, 551, 23, 6144, 28476, 590, 1233, 6, 562, 69, 222, 218, 14, 52, 19, 83, 5, 871, 19, 5350, 7, 9, 482, 6358, 28464, 429, 551, 13, 48, 2604, 7, 4495, 6, 526, 97, 48, 755, 17555, 7, 9, 482, 9748, 28464, 429, 551, 11, 645, 15, 16, 33, 8, 3222, 59, 14294, 13, 139, 7786, 712, 7, 9, 6376, 14, 22649, 28614, 6, 6089, 701, 14524, 5, 482, 9505, 28499, 429, 551, 13, 1411, 276, 453, 12, 12366, 5, 15142, 8, 18060, 57, 180, 14, 656, 15, 10, 881, 28, 31, 3635, 205, 14, 6, 6093, 16562, 2371, 49, 534, 4093, 6, 2202, 23957, 893, 14484, 28687, 17658, 5, 416, 5205, 126, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
    """

    # dataloader
    dataloader_train = LivedoorNewsDataLoader(
        network.tokenizer, tokenizer_params_input={"padding": True, "max_length": network.tokenizer.model_max_length, "truncation": True}, 
        aftprocs=[lambda x, y: [dict(x), y]],
        train=True, download=True, batch_size=32, shuffle=True, num_workers=8
    )
    dataloader_valid = LivedoorNewsDataLoader(
        network.tokenizer, tokenizer_params_input={"padding": True, "max_length": network.tokenizer.model_max_length, "truncation": True}, 
        aftprocs=[lambda x, y: [dict(x), y]],
        train=False, download=True, batch_size=32, shuffle=False, num_workers=8
    )
    """
    >>> dataloader_train.sample()
    [{'input_ids': tensor([[    2,  5938,     5,  ...,     0,     0,     0],
        [    2,  1758,     5,  ...,     0,     0,     0],
        [    2, 25689, 29354,  ...,    34,     8,     3],
        ...,
        [    2,   580,    14,  ...,  6343,  6032,     3],
        [    2,  8485, 10731,  ...,    36, 18532,     3],
        [    2,  2381,     5,  ...,    19,     5,     3]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]])}, tensor([4, 8, 2, 5, 7, 7, 1, 1, 8, 0, 0, 4, 5, 6, 6, 3])]
    """

    trainer = Trainer(
        network,
        losses_train=torch.nn.CrossEntropyLoss(),
        losses_valid=[[torch.nn.CrossEntropyLoss(), kktorch.nn.Accuracy()]],
        losses_train_name="ce",
        losses_valid_name=["ce", "acc"], 
        optimizer={"optimizer": torch.optim.AdamW, "params": dict(lr=1e-4)}, 
        dataloader_train =dataloader_train, dataloader_valids=dataloader_valid,
        auto_mixed_precision=True, epoch=5, valid_step=200, valid_iter=10, print_step=200, 
    )

    # to cuda
    trainer.to_cuda()

    # training
    trainer.train()